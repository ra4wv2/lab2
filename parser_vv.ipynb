{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from lxml import html\n",
    "import urllib.request\n",
    "import re\n",
    "\n",
    "pages = []\n",
    "hrefs = []\n",
    "\n",
    "for i in range(1, 3985):\n",
    "    url = 'https://vv-34.ru/all/page-'+str(i)\n",
    "    pages.append(url)\n",
    "    \n",
    "with open('urls.txt', 'a') as urls:\n",
    "    for each in pages:\n",
    "        f = urllib.request.urlopen(each)\n",
    "        file = f.read()\n",
    "        soup = BeautifulSoup(file)\n",
    "        newentries = soup.find_all('div', {'class': 'newentry'})\n",
    "        rightcats = soup.find_all('div', {'class': 'rightcat'})\n",
    "        for eachh in rightcats:\n",
    "            a = eachh.find_all('a', href=True)[0]\n",
    "            new = 'https://vv-34.ru' + str(a.get('href'))[:-2]\n",
    "            urls.write(new+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from lxml import html\n",
    "import urllib.request\n",
    "import re\n",
    "from lxml import etree\n",
    "\n",
    "\n",
    "with open('urls.txt') as all_urls:\n",
    "    urli = all_urls.read().split()\n",
    "    def scrapper():\n",
    "        for url in urli:\n",
    "            stranica = []\n",
    "            full_text = []\n",
    "            stranica.append('######')\n",
    "            stranica.append('URL: ' + url)\n",
    "            stranica.append('Источник: Вечерний Волгоград')\n",
    "            f = urllib.request.urlopen(url)\n",
    "            file = f.read()\n",
    "            soup = BeautifulSoup(file)\n",
    "            con_pubdate = soup.find('div', {'class': 'con_pubdate'})\n",
    "            try:\n",
    "                con_heading = soup.find('h1', {'class': 'con_heading'})\n",
    "                heading = 'Название статьи: ' + con_heading.text\n",
    "            except AttributeError:\n",
    "                heading = 'Название статьи не указано'\n",
    "            pattern = '\\n|\\t|\\s'\n",
    "            dat = con_pubdate.text\n",
    "            dt = re.sub(pattern, '', dat)\n",
    "            months = {'января': '.01.', 'февраля': '.02.', 'марта': '.03.', 'апреля': '.04.', 'мая': '.05.', 'июня': '.06.', 'июля': '.07.', 'августа': '.08.', 'сентября': '.09.', 'октября': '.10.', 'ноября': '.11.', 'декабря': '.12.'}\n",
    "            pat = '[а-я]+'\n",
    "            dtt = re.findall(pat, dt)\n",
    "            d = re.sub(dtt[0], months[dtt[0]], dt)          \n",
    "            date = 'Дата: ' + d\n",
    "            stranica.append(date)\n",
    "            stranica.append(heading)\n",
    "            artconts = soup.find_all('div', {'class': 'artcont'})\n",
    "            for each in artconts:     \n",
    "                try:\n",
    "                    em = each.find_all('em')[0]\n",
    "                    author = 'Автор: '+ em.text\n",
    "                    stranica.append(author)\n",
    "                except IndexError:\n",
    "                    stranica.append('Автор не указан')\n",
    "                try:\n",
    "                    for i in range(len(each.find_all('p'))):\n",
    "                        al = each.find_all('p')[i]\n",
    "                        #print(al)\n",
    "                        full_text.append(al.text)\n",
    "                except IndexError:\n",
    "                    pass\n",
    "                #print(full_text)\n",
    "                for i in range(len(each.find_all('span', attrs={'style': 'font-size:16px;'}))):\n",
    "                    span = each.find_all('span', attrs={'style': 'font-size:16px;'})[i]\n",
    "                    if span.text not in stranica:\n",
    "                        a = span.text.split('\\n')\n",
    "                        full_text.append(a[0])\n",
    "            textt = ' '.join(full_text)\n",
    "            pttrn = '\\n|\\t'\n",
    "            tex = re.sub(pttrn, '', textt)\n",
    "            stranica.append(tex)\n",
    "            strnc = '\\n'.join(stranica)\n",
    "            with open ('data.txt', 'a', encoding='utf-8') as data:\n",
    "                data.write(strnc + '\\n')\n",
    "                \n",
    "    while True:\n",
    "        try:\n",
    "            scrapper()\n",
    "            break\n",
    "        except TimeoutError:\n",
    "            sleep(10)\n",
    "            print('ops')\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
